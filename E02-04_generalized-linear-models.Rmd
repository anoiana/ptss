---
params:
  update_date: FALSE
  run_chunk: FALSE
date: "`r source('_supp/helper.R'); newdate_func(params$update_date)`"
title: "`r totitle('generalized linear models')`"
output: 
  bookdown::html_document2:
    code_folding: hide
    number_sections: true
bibliography: ["_supp/citation.bib"]
link-citations: true
---

\newcommand{\bf}[1]{\boldsymbol{#1}}
\newcommand{\hat}[1]{\widehat{#1}}
\newcommand{\mm}[1]{\mathbb{#1}}
\newcommand{\bar}[1]{\overline{#1}}
\newcommand{\tp}[1]{{#1}^{\top}}

\def\E{\Bbb{E}}
\def\V{\Bbb{V}}
\def\P{\Bbb{P}}
\def\I{{\large\unicode{x1D7D9}}}
\def\indep{\perp\!\!\!\!\perp}
\newcommand{\overeq}[2]{\stackrel{#1}{#2}}
\def\epsilon{\varepsilon} 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
ttt = purrr::partial(totitle, icon = "")
```

::: {.watermark}
*DRAFT*
:::

::: {.right .shad}
[refer to @dem2013]
:::
---

# `r ttt('Regression models for binary data')`

Let us denote response variable as $\{y_i \in \{0,1\}\}_{i=1,2,\dots,n}$ and $\{\bf{x}_i \in \mathbb{R}^{m\times 1}\}_{i=1,2,\dots,n}$ be covariates of subject $i$.  Thus, 
$$
p = \P(y_i = 1) = \mu(\tp{\bf{\beta}}\bf{x}_i), \quad i = 1,2,\dots,n,
(\#eq:eq11)
$$
where $\bf{\beta} \in \mathbb{R}^{m\times 1}$ is coefficients and $\mu = \eta^{-1}$ is the inverse link function, and hence $\eta(\P(y_i=1)) = \tp{\bf{\beta}}\bf{x}_i$. Thus, $(y_i,\bf{x}_i)$ is a realization of subject $i$. To illuminate this scenario to statistics framework, we have 
$$
y_i \sim \mathcal{Bin}(1,\P(y_i=1)), \\
\Rightarrow \E(y_i) = \mu(\tp{\bf{\beta}}\bf{x}_i), \text{ and} \quad
\V(y_i) = \mu(\tp{\bf{\beta}}\bf{x}_i)[1-\mu(\tp{\bf{\beta}}\bf{x}_i)]
$$

Some options of $\eta$ comprise

- $\eta = logit(p) = \frac{p}{1-p}$, logistic regression.
- $\eta = \Phi^{-1}(p)$, probit regression.
- $\eta = \log[-\log(p)]$, log-log regression. 

In logistic model, an effect size used widely is *odd ratio* that is defined as follows
$$
OR_1 = \frac{\P(y=1|x_i =1)}{\P(y=0,x_i=1)} = \exp(\beta_0 + \beta_1)
$$
and 
$$
OR_0 = \frac{\P(y=1|x_i =0)}{\P(y=0,x_i=0)} = \exp(\beta_0)
$$
and hence
$$
\ln(OR_1) - \ln(OR_0) = \beta_1
$$
is  relative effect between two groups categorized by binary variable $x_i$, note that $\bf{x}_i \in \mathbb{R}^{1\times 1}$. For more information of probit and log-log link, see @dem2013.

## `r ttt('connection of logit and probit')`




## `r ttt('logistic-normal integral')`

*logistic-normal integral* plays an important role in logistic model with normally distributed covariate measurement error.  The logistic-normal integral is improper 
$$
I = I(s,\sigma^2) = \frac{1}{\sigma\sqrt{2\pi}}\int_{-\infty}^{\infty}\frac{e^x}{1+e^x}\exp\Big[-\frac{1}{2\sigma^2}(x-s)^2\Big]dx.
(\#eq:eq12)
$$

After standardize variable we obtain
$$
I = \frac{1}{\sigma\sqrt{2\pi}}\int_{-\infty}^{\infty}\frac{e^{s+\sigma x}}{1+ e^{s+\sigma x}}e^{-\frac{1}{2}x^2}dx.
(\#eq:eq13)
$$
`r lb(eq13)` can be considered as 
$$
I = \E_{u \sim \mathcal{N}(0,1)}\frac{e^{s+\sigma u}}{1+ e^{s+\sigma u}}
$$
$I$ can be approximated by 
$$
\E_{u \sim \mathcal{N}(0,\sigma^2)}\Phi(s+u) = \Phi\bigg(\frac{s}{\sqrt{1+\sigma^2}}\bigg),
(\#eq:eq14)
$$
the proof of `r lb(eq14)` can be found on page 339, @dem2013. 

Another approximation of logistic-normal integral is to approximate the link function first and then apply the back transformation, we call the approximation of the link function is *link-approximation*. We knew logistic link function is 
$$
\ln\bigg[\frac{\mu_L}{1-\mu_L}\bigg], \text{ where} \quad \mu_L(s) = \frac{e^s}{1+e^s},
$$ 
We introduce a function of $\sigma$,
$$
\begin{align}
R(\sigma) &= \ln\bigg[\frac{\E_{u \sim \mathcal{N}(0,1)}\frac{\exp[s+\sigma u]}{1+\exp[s+\sigma u]}}{\E_{u \sim \mathcal{N}(0,1)}\frac{1}{1+\exp[s+\sigma u]}} \bigg] \\
&= \ln\E_{u \sim \mathcal{N}(0,1)}\frac{\exp[s+\sigma u]}{1+\exp[s+\sigma u]} - \ln\E_{u \sim \mathcal{N}(0,1)}\frac{1}{1+\exp[s+\sigma u]},
\end{align}
(\#eq:eq15)
$$
and $R(0) = s$
If taking derivative of `r lb(eq15)`, we obtain
$$
\frac{dR(\sigma)}{d\sigma} = \bigg[\bigg(E_{u \sim \mathcal{N}(0,1)}\frac{\exp[s+\sigma u]}{1+\exp[s+\sigma u]}\bigg)^{-1}+ \bigg(\E_{u \sim \mathcal{N}(0,1)}\frac{1}{1+\exp[s+\sigma u]}\bigg)^{-1}\bigg]\E_{u \sim \mathcal{N}(0,1)}\bigg[\frac{\exp(s+\sigma u)}{(1+\exp[s+\sigma u])^2}u\bigg].
(\#eq:eq16)
$$

Since $u \sim \mathcal{N}(0,1)$, $\E(u) = 0$. Hence, $\frac{d^2R(\sigma)}{d\sigma^2}\bigg|_{\sigma=0} = 0$. We also find second derivative at $\sigma=0$, 
$$
\begin{align}
\frac{d^2}{d\sigma^2}R(\sigma)\bigg|_{\sigma = 0} &= \bigg[\frac{1+e^s}{e^s}+1+e^s\bigg]\E_u\bigg[\frac{e^s(1-e^2)}{(1+e^2)^3}u^2\bigg] \\
&= \bigg[\frac{1+e^s}{e^s}+1+e^s\bigg]\frac{e^s(1-e^s)}{(1+e^s)^3} \\
&= \frac{1-e^s}{1+e^s},
\end{align}
(\#eq:eq17)
$$
since $\E(u^2) = 1$. 

:::: {.blackbox .brainstorm}
::: {.center}
proof of `r lb(eq17)`:
:::
Let $dR(\sigma)/d\sigma = (k_1^{-1}+k_2^{-1})k_3$ with $k_1, k_2$ and $k_3$ are relative to each term in `r lb(eq16)`. Hence, $d^2R(\sigma)/d\sigma^2 = (k_1^{-1}+k_2^{-1})'k_3 + (k_1^{-1}+k_2^{-1})k'_3$. 

We have $(1/v)' = -\ln(v)'/v$. Let $v = \E_u\frac{e^{s+\sigma u}}{1+ e^{s+\sigma u}}$, and then 
$$
\bigg[\bigg(E_{u \sim \mathcal{N}(0,1)}\frac{\exp[s+\sigma u]}{1+\exp[s+\sigma u]}\bigg)^{-1}\bigg]' = \frac{\E_{u \sim \mathcal{N}(0,1)}\bigg[\frac{\exp(s+\sigma u)}{(1+\exp[s+\sigma u])^2}u\bigg]}{\bigg(\E_{u \sim \mathcal{N}(0,1)}\frac{\exp[s+\sigma u]}{1+\exp[s+\sigma u]}\bigg)^2}\bigg|_{\sigma=0} = 0
$$
Similarly, if $v = \E_u\frac{1}{1+ e^{s+\sigma u}}$, we also have 
$$
\bigg[\bigg(E_{u \sim \mathcal{N}(0,1)}\frac{1}{1+\exp[s+\sigma u]}\bigg)^{-1}\bigg]' = \frac{\E_{u \sim \mathcal{N}(0,1)}\bigg[\frac{\exp(s+\sigma u)}{(1+\exp[s+\sigma u])^2}u\bigg]}{\bigg(\E_{u \sim \mathcal{N}(0,1)}\frac{1}{1+\exp[s+\sigma u]}\bigg)^2}\bigg|_{\sigma=0} = 0.
$$

Thus, $(k_1^{-1}+k_2^{-1})'k_3 = 0$, and $d^2R(\sigma)/d\sigma^2 = (k_1^{-1}+k_2^{-1})k'_3$. We see that 
$$
k_3' = \E_{u \sim \mathcal{N}(0,1)}\bigg[\frac{e^s(1-e^s)}{(1+e^s)^3}u^2\bigg] = \frac{e^s(1-e^s)}{(1+e^s)^3}
(\#eq:eq18)
$$
since $\E(u^2) = 0$. and
$$
k_1^{-1}+k_2^{-1}\bigg|_{\sigma=0} = \frac{1+e^s}{e^s}+1+e^s.
(\#eq:eq19)
$$
From `r lb(eq18)` and `r lb(eq19)` we obtain `r lb(eq17)`. $\quad \blacksquare$
::::

Also, we have 
$$
\frac{dR(\sigma)}{d\sigma} = \frac{dR(\sigma)}{d(\sigma^2)}\frac{d(\sigma^2)}{d\sigma} = \frac{dR(\sigma)}{d(\sigma^2)}(2\sigma),
$$
so
$$
\frac{d^2R(\sigma)}{d\sigma^2} = 2(\sigma^2)^{1/2}\frac{d}{d\sigma}\frac{dR(\sigma)}{d(\sigma^2)} + 2\frac{dR(\sigma)}{d(\sigma^2)}
$$
as $\sigma^2 =0 \Rightarrow \sigma = 0$, we see the first term on right-hand side equals zero no matter what $\frac{d}{d\sigma}\frac{dR(\sigma)}{d(\sigma^2)}$ is, and hence
$$
\frac{dR(\sigma)}{d(\sigma^2)}\bigg|_{\sigma^2=0} = \frac{\frac{d^2R(\sigma)}{d\sigma^2}\bigg|_{\sigma=0}}{2} = \frac{1}{2}\frac{1-e^s}{1+e^s}
(\#eq:eq110)
$$





















<!-- ----------------------------------------------------------------------------- -->

::: {.shad}
# _References_ {-}
:::
