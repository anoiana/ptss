---
params:
  update_date: FALSE
  run_chunk: FALSE
date: "`r source('_supp/helper.R'); newdate_func(params$update_date)`"
title: "`r totitle('generalized linear models')`"
output: 
  bookdown::html_document2:
    code_folding: hide
    number_sections: true
bibliography: ["_supp/citation.bib"]
link-citations: true
---

\newcommand{\bf}[1]{\boldsymbol{#1}}
\newcommand{\hat}[1]{\widehat{#1}}
\newcommand{\mm}[1]{\mathbb{#1}}
\newcommand{\bar}[1]{\overline{#1}}
\newcommand{\tp}[1]{{#1}^{\top}}

\def\E{\Bbb{E}}
\def\V{\Bbb{V}}
\def\P{\Bbb{P}}
\def\I{{\large\unicode{x1D7D9}}}
\def\indep{\perp\!\!\!\!\perp}
\newcommand{\overeq}[2]{\stackrel{#1}{#2}}
\def\epsilon{\varepsilon} 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
ttt = purrr::partial(totitle, icon = "")
```

::: {.watermark}
*DRAFT*
:::

::: {.right .shad}
[refer to @dem2013]
:::
---

# `r ttt('Regression models for binary data')`

Let us denote response variable as $\{y_i \in \{0,1\}\}_{i=1,2,\dots,n}$ and $\{\bf{x}_i \in \mathbb{R}^{m\times 1}\}_{i=1,2,\dots,n}$ be covariates of subject $i$.  Thus, 
$$
p = \P(y_i = 1) = \mu(\tp{\bf{\beta}}\bf{x}_i), \quad i = 1,2,\dots,n,
(\#eq:eq11)
$$
where $\bf{\beta} \in \mathbb{R}^{m\times 1}$ is coefficients and $\mu = \eta^{-1}$ is the inverse link function, and hence $\eta(\P(y_i=1)) = \tp{\bf{\beta}}\bf{x}_i$. Thus, $(y_i,\bf{x}_i)$ is a realization of subject $i$. To illuminate this scenario to statistics framework, we have 
$$
y_i \sim \mathcal{Bin}(1,\P(y_i=1)), \\
\Rightarrow \E(y_i) = \mu(\tp{\bf{\beta}}\bf{x}_i), \text{ and} \quad
\V(y_i) = \mu(\tp{\bf{\beta}}\bf{x}_i)[1-\mu(\tp{\bf{\beta}}\bf{x}_i)]
$$

Some options of $\eta$ comprise

- $\eta = logit(p) = \frac{p}{1-p}$, logistic regression.
- $\eta = \Phi^{-1}(p)$, probit regression.
- $\eta = \log[-\log(p)]$, log-log regression. 

In logistic model, an effect size used widely is *odd ratio* that is defined as follows
$$
OR_1 = \frac{\P(y=1|x_i =1)}{\P(y=0,x_i=1)} = \exp(\beta_0 + \beta_1)
$$
and 
$$
OR_0 = \frac{\P(y=1|x_i =0)}{\P(y=0,x_i=0)} = \exp(\beta_0)
$$
and hence
$$
\ln(OR_1) - \ln(OR_0) = \beta_1
$$
is  relative effect between two groups categorized by binary variable $x_i$, note that $\bf{x}_i \in \mathbb{R}^{1\times 1}$. For more information of probit and log-log link, see @dem2013.

## `r ttt('connection of logit and probit')`
<!-- add-on section, different style of label -->

In this section, we deem relationship between logistic and probit link function, which is essential in next section in which we shall learn how to approximate logistic by probit link.  Let 
$$
\mu_L(s) = \frac{e^s}{1+e^s},
$$
hence we have 
$$
\mu_L(s) \approx \Phi\Big(\frac{s}{c}\Big),
(\#eq:eq11a)
$$
the next aim is to determine value of $c$ such that `r lb(eq11a)` is true. As $s=0$ `r lb(eq11a)` is always true. Also, derivative of $\mu_L(s)$ equal $1/4$ as $s=0$ and derivative of $\Phi(s/c) = (1/c)(1/\sqrt{2\pi})$. To equate both derivatives, $c = \sqrt{8/\pi}$. To understand the logic we consider `r lb(eq11a)` with $c$ is chosen arbitrarily. 

```{r fig11, fig.cap="logistic and probit functions with different values of $c$.", fig.align='center'}
s = seq(-5,5,length.out = 100)
mu = function(s) exp(s)/(1+exp(s))
phi = function(s,v) pnorm(s/v)
v = c(0.5,2,3,4)
par(mfrow = c(2,2))
for(i in v){
plot(s,mu(s), type = "l", xlab = "", ylab = "")
points(s, phi(s,v = i), type = "l", col = "red")
legend("topleft", legend = c(expression(mu(s)), expression(Phi(s/c))),
       col = c("black","red"),
       lty = 1
       )
text(2,0.1, paste("c = ",i))
}
```

`r lb(fig11)` depicts function of $\mu(s)$ and $\Phi(s/c)$, both functions are equal as $s = 0$, if we can adjust $\Phi(s/c)$ such that its two critical points approximate to that of $\mu(s)$, then $\mu(s)$ can be approximated by $\Phi(s)$. To this end, we will adjust $c$ such that $\mu'(s) = \Phi'(s/c)$. 

Another approximation can be sought by minimax method, i.e. we maximize the difference of both functions $\mu(s)$ and $\Phi(s/c)$ w.r.t $s$ and minimize it w.r.t $c$, this can be solved numerically. Then we obtain $c = 16\sqrt{3}/15\pi$. 

Also, we can approximate $\mu(s)$ by 2 probit links as follows
$$
\mu_L(s) \approx p\Phi(s/c_1) + (1-p)\Phi(s/c_2)
(\#eq:eq12a)
$$
and the objective function w.r.t `r lb(eq12a)` is
$$
\int^{\infty}_{-\infty}\bigg[\mu_L(s) - p\Phi(s/c_1) - (1-p)\Phi(s/c_2)\bigg]^2ds.
$$
Thus `r lb(eq12a)` is equivalent to 

::: {.rectangle style="border: thin solid black; padding-left: 10px;"}
$$
\mu_L(s) \approx 0.4353\Phi(s/2.2967) + 0.5647\Phi(s/1.3017).
(\#eq:eq13a)
$$
:::

## `r ttt('logistic-normal integral')`

*logistic-normal integral* plays an important role in logistic model with normally distributed covariate measurement error.  The logistic-normal integral is improper 
$$
I = I(s,\sigma^2) = \frac{1}{\sigma\sqrt{2\pi}}\int_{-\infty}^{\infty}\frac{e^x}{1+e^x}\exp\Big[-\frac{1}{2\sigma^2}(x-s)^2\Big]dx.
(\#eq:eq12)
$$

After standardize variable we obtain
$$
I = \frac{1}{\sigma\sqrt{2\pi}}\int_{-\infty}^{\infty}\frac{e^{s+\sigma x}}{1+ e^{s+\sigma x}}e^{-\frac{1}{2}x^2}dx.
(\#eq:eq13)
$$
`r lb(eq13)` can be considered as 
$$
I = \E_{u \sim \mathcal{N}(0,1)}\frac{e^{s+\sigma u}}{1+ e^{s+\sigma u}}
$$
$I$ can be approximated by 
$$
\E_{u \sim \mathcal{N}(0,\sigma^2)}\Phi(s+u) = \Phi\bigg(\frac{s}{\sqrt{1+\sigma^2}}\bigg),
(\#eq:eq14)
$$
the proof of `r lb(eq14)` can be found on page 339, @dem2013. 

From `r lb(eq12a)` we can approximate $I$
$$
I \approx \E_{u \sim \mathcal{N}(0,1)}\Phi\bigg(\frac{s+\sigma u}{c}\bigg) = \E_{k \sim \mathcal{N}(0,\sigma^2/c^2)}\Phi(c^{-1}s + k),
$$
where $k = \sigma u/c$. Thus, 
$$
I \approx \Phi\Big(\frac{c^{-1}s}{\sqrt{1+ \sigma^2/c^2}}\Big) = \Phi\Big(\frac{s}{\sqrt{c^2+\sigma^2}}\Big) = \Phi\Big(\frac{s}{\sqrt{1.7^2+\sigma^2}}\Big)
$$
We chose $c = 1.7 \approx \sqrt{8/\pi}$ since if $\sigma^2 = 0$, $I = e^s/(1+e^s) \approx \Phi(s/c)|_{c=1.7}$.

Another approximation of logistic-normal integral is to approximate the link function first and then apply the back transformation, we call the approximation of the link function is *link-approximation*. We knew logistic link function is 
$$
\ln\bigg[\frac{\mu_L}{1-\mu_L}\bigg], \text{ where} \quad \mu_L(s) = \frac{e^s}{1+e^s},
$$ 
We introduce a function of $\sigma$,
$$
\begin{align}
R(\sigma) &= \ln\bigg[\frac{\E_{u \sim \mathcal{N}(0,1)}\frac{\exp[s+\sigma u]}{1+\exp[s+\sigma u]}}{\E_{u \sim \mathcal{N}(0,1)}\frac{1}{1+\exp[s+\sigma u]}} \bigg] \\
&= \ln\E_{u \sim \mathcal{N}(0,1)}\frac{\exp[s+\sigma u]}{1+\exp[s+\sigma u]} - \ln\E_{u \sim \mathcal{N}(0,1)}\frac{1}{1+\exp[s+\sigma u]},
\end{align}
(\#eq:eq15)
$$
and $R(0) = s$
If taking derivative of `r lb(eq15)`, we obtain
$$
\frac{dR(\sigma)}{d\sigma} = \bigg[\bigg(E_{u \sim \mathcal{N}(0,1)}\frac{\exp[s+\sigma u]}{1+\exp[s+\sigma u]}\bigg)^{-1}+ \bigg(\E_{u \sim \mathcal{N}(0,1)}\frac{1}{1+\exp[s+\sigma u]}\bigg)^{-1}\bigg]\E_{u \sim \mathcal{N}(0,1)}\bigg[\frac{\exp(s+\sigma u)}{(1+\exp[s+\sigma u])^2}u\bigg].
(\#eq:eq16)
$$

Since $u \sim \mathcal{N}(0,1)$, $\E(u) = 0$. Hence, $\frac{d^2R(\sigma)}{d\sigma^2}\bigg|_{\sigma=0} = 0$. We also find second derivative at $\sigma=0$, 
$$
\begin{align}
\frac{d^2}{d\sigma^2}R(\sigma)\bigg|_{\sigma = 0} &= \bigg[\frac{1+e^s}{e^s}+1+e^s\bigg]\E_u\bigg[\frac{e^s(1-e^2)}{(1+e^2)^3}u^2\bigg] \\
&= \bigg[\frac{1+e^s}{e^s}+1+e^s\bigg]\frac{e^s(1-e^s)}{(1+e^s)^3} \\
&= \frac{1-e^s}{1+e^s},
\end{align}
(\#eq:eq17)
$$
since $\E(u^2) = 1$. 

:::: {.blackbox .brainstorm}
::: {.center}
proof of `r lb(eq17)`:
:::
Let $dR(\sigma)/d\sigma = (k_1^{-1}+k_2^{-1})k_3$ with $k_1, k_2$ and $k_3$ are relative to each term in `r lb(eq16)`. Hence, $d^2R(\sigma)/d\sigma^2 = (k_1^{-1}+k_2^{-1})'k_3 + (k_1^{-1}+k_2^{-1})k'_3$. 

We have $(1/v)' = -\ln(v)'/v$. Let $v = \E_u\frac{e^{s+\sigma u}}{1+ e^{s+\sigma u}}$, and then 
$$
\bigg[\bigg(E_{u \sim \mathcal{N}(0,1)}\frac{\exp[s+\sigma u]}{1+\exp[s+\sigma u]}\bigg)^{-1}\bigg]' = \frac{\E_{u \sim \mathcal{N}(0,1)}\bigg[\frac{\exp(s+\sigma u)}{(1+\exp[s+\sigma u])^2}u\bigg]}{\bigg(\E_{u \sim \mathcal{N}(0,1)}\frac{\exp[s+\sigma u]}{1+\exp[s+\sigma u]}\bigg)^2}\bigg|_{\sigma=0} = 0
$$
Similarly, if $v = \E_u\frac{1}{1+ e^{s+\sigma u}}$, we also have 
$$
\bigg[\bigg(E_{u \sim \mathcal{N}(0,1)}\frac{1}{1+\exp[s+\sigma u]}\bigg)^{-1}\bigg]' = \frac{\E_{u \sim \mathcal{N}(0,1)}\bigg[\frac{\exp(s+\sigma u)}{(1+\exp[s+\sigma u])^2}u\bigg]}{\bigg(\E_{u \sim \mathcal{N}(0,1)}\frac{1}{1+\exp[s+\sigma u]}\bigg)^2}\bigg|_{\sigma=0} = 0.
$$

Thus, $(k_1^{-1}+k_2^{-1})'k_3 = 0$, and $d^2R(\sigma)/d\sigma^2 = (k_1^{-1}+k_2^{-1})k'_3$. We see that 
$$
k_3' = \E_{u \sim \mathcal{N}(0,1)}\bigg[\frac{e^s(1-e^s)}{(1+e^s)^3}u^2\bigg] = \frac{e^s(1-e^s)}{(1+e^s)^3}
(\#eq:eq18)
$$
since $\E(u^2) = 0$. and
$$
k_1^{-1}+k_2^{-1}\bigg|_{\sigma=0} = \frac{1+e^s}{e^s}+1+e^s.
(\#eq:eq19)
$$
From `r lb(eq18)` and `r lb(eq19)` we obtain `r lb(eq17)`. $\quad \blacksquare$
::::

Also, we have 
$$
\frac{dR(\sigma)}{d\sigma} = \frac{dR(\sigma)}{d(\sigma^2)}\frac{d(\sigma^2)}{d\sigma} = \frac{dR(\sigma)}{d(\sigma^2)}(2\sigma),
$$
so
$$
\frac{d^2R(\sigma)}{d\sigma^2} = 2(\sigma^2)^{1/2}\frac{d}{d\sigma}\frac{dR(\sigma)}{d(\sigma^2)} + 2\frac{dR(\sigma)}{d(\sigma^2)}
$$
as $\sigma^2 =0 \Rightarrow \sigma = 0$, we see the first term on right-hand side equals zero no matter what $\frac{d}{d\sigma}\frac{dR(\sigma)}{d(\sigma^2)}$ is, and hence
$$
\frac{dR(\sigma)}{d(\sigma^2)}\bigg|_{\sigma^2=0} = \frac{\frac{d^2R(\sigma)}{d\sigma^2}\bigg|_{\sigma=0}}{2} = \frac{1}{2}\frac{1-e^s}{1+e^s}
(\#eq:eq110)
$$





















<!-- ----------------------------------------------------------------------------- -->

::: {.shad}
# _References_ {-}
:::
